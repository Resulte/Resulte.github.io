---
layout:     post                    
title:      深度学习学习笔记3-softmax回归              
subtitle:   Dive into deep learning 
date:       2020-10-16              
author:     Resulte                      
header-img: img/post-bg-universe.jpg 
catalog: true                       
tags:                               
    - 深度学习

---

# 深度学习学习笔记3-softmax回归

### 一、简介

线性回归模型适用于输出为连续值的情景。在另一类情景中，模型输出可以是一个像图像类别这样的离散值。对于这样的离散值预测问题，我们可以使用诸如softmax回归在内的分类模型。和线性回归不同，softmax回归的输出单元从一个变成了多个，且引入了softmax运算使输出更适合离散值的预测和训练。

线性回归和softmax回归都是单层神经网络。

### 二、例子

让我们考虑一个简单的图像分类问题，其输入图像的高和宽均为2像素，且色彩为灰度。这样每个像素值都可以用一个标量表示。我们将图像中的4像素分别记为x1,x2,x3,x4。假设训练数据集中图像的真实标签为狗、猫或鸡（假设可以用4像素表示出这3种动物），这些标签分别对应离散值y1,y2,y3。

我们通常使用离散的数值来表示类别，例如y1=1,y2=2,y3=3。如此，一张图像的标签为1、2和3这3个数值中的一个。虽然我们仍然可以使用回归模型来进行建模，并将预测值就近定点化到1、2和3这3个离散值之一，但这种连续值到离散值的转化通常会影响到分类质量。因此我们一般使用更加适合离散值输出的模型来解决分类问题。

### 三、模型

softmax回归跟线性回归一样将输入特征与权重做线性叠加。与线性回归的一个主要不同在于，softmax回归的输出值个数等于标签里的类别数。因为一共有4种特征和3种输出动物类别，所以权重包含12个标量（带下标的w）、偏差包含3个标量（带下标的b），且对每个输入计算o1,o2,o3这3个输出：

o1=x1w11+x2w21+x3w31+x4w41+b1,
o2=x1w12+x2w22+x3w32+x4w42+b2,
o3=x1w13+x2w23+x3w33+x4w43+b3.

### 四、softmax运算

既然分类问题需要得到离散的预测输出，一个简单的办法是将输出值oi当作预测类别是ii的置信度，并将值最大的输出所对应的类作为预测输出。例如，如果o1,o2,o3分别为0.1,10,0.1，由于o2最大，那么预测类别为2，其代表猫。

然而，直接使用输出层的输出有两个问题。一方面，由于输出层的输出值的范围不确定，我们难以直观上判断这些值的意义。例如，刚才举的例子中的输出值10表示“很置信”图像类别为猫，因为该输出值是其他两类的输出值的100倍。但如果o1=o3=10^3，那么输出值10却又表示图像类别为猫的概率很低。另一方面，由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。

softmax运算符（softmax operator）解决了以上两个问题。它通过下式将输出值变换成值为正且和为1的概率分布：
$$
ŷ 1,ŷ 2,ŷ 3=softmax(o1,o2,o3),
$$
容易看出ŷ 1+ŷ 2+ŷ 3=1且0≤ŷ 1,ŷ 2,ŷ 3≤1，因此ŷ 1,ŷ 2,ŷ 3是一个合法的概率分布。这时候，如果ŷ 2=0.8，不管ŷ 1和ŷ 3的值是多少，我们都知道图像类别为猫的概率是80%。因此softmax运算不改变预测类别输出。

### 五、模型预测

模型训练完成后，我们将模型参数w1,w2,b在优化算法停止时的值分别记作ŵ 1,ŵ 2,b̂ 。注意，这里我们得到的并不一定是最小化损失函数的最优解，而是对最优解的一个近似。然后，我们就可以使用学出的线性回归模型x1ŵ 1+x2ŵ 2+b̂ 来估算训练数据集以外任意一栋面积（平方米）为x1、房龄（年）为x2的房屋的价格了。这里的估算也叫作模型预测、模型推断或模型测试。